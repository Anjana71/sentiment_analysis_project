{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORQoXCk+rMxwmTyd6w0zzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjana71/sentiment_analysis_project/blob/main/sentiment_analysis_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/archive (2).zip\"\n",
        "extract_dir = \"/content/emotion_data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"‚úÖ Extracted contents:\")\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    print(f\"üìÅ {root}\")\n",
        "    for file in files:\n",
        "        print(f\"    üìÑ {file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI8XUwo1PtCa",
        "outputId": "800534f0-9c94-4bad-b025-12e987849105"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted contents:\n",
            "üìÅ /content/emotion_data\n",
            "    üìÑ val.txt\n",
            "    üìÑ train.txt\n",
            "    üìÑ test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_emotion_data(folder_path):\n",
        "    texts, labels = [], []\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".txt\"):\n",
        "                with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as f:\n",
        "                    for line in f:\n",
        "                        if \";\" in line:\n",
        "                            parts = line.strip().split(\";\")\n",
        "                            if len(parts) == 2:\n",
        "                                text, label = parts\n",
        "                                if text.strip() and label.strip():\n",
        "                                    texts.append(text.strip())\n",
        "                                    labels.append(label.strip())\n",
        "    return pd.DataFrame({\"text\": texts, \"label\": labels})\n"
      ],
      "metadata": {
        "id": "_u61mgyBP0Rs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_single_file(path):\n",
        "    texts, labels = [], []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(';')\n",
        "            if len(parts) == 2:\n",
        "                text, label = parts\n",
        "                if text.strip() and label.strip():\n",
        "                    texts.append(text.strip())\n",
        "                    labels.append(label.strip())\n",
        "    return pd.DataFrame({\"text\": texts, \"label\": labels})\n",
        "\n",
        "# Load each file\n",
        "train_df = load_single_file(\"/content/emotion_data/train.txt\")\n",
        "val_df = load_single_file(\"/content/emotion_data/val.txt\")\n",
        "test_df = load_single_file(\"/content/emotion_data/test.txt\")\n",
        "\n",
        "# Combine them\n",
        "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "# Preview\n",
        "print(f\"‚úÖ Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)} | Total: {len(df)}\")\n",
        "print(df.sample(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9b_fGivP4PY",
        "outputId": "ff20ebed-4e2f-434c-f971-c12ace7ec1f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Train: 16000 | Val: 2000 | Test: 2000 | Total: 20000\n",
            "                                                    text    label\n",
            "10680  i am still numb i question everything about wh...     fear\n",
            "19761  i write this i giggle and shake my head in hum...      joy\n",
            "9229           i know but it still feels very unpleasant  sadness\n",
            "16239  i feel strongly that those who finger point an...      joy\n",
            "11367  i get the feeling that if the tabloids either ...  sadness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "df['cleaned'] = df['text'].apply(clean_text)\n",
        "\n",
        "X = df['cleaned']\n",
        "y = df['label']\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Model trained\")\n",
        "print(classification_report(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCH0-eOrQ_q-",
        "outputId": "ad007d43-bfbb-4e79-e22c-7f8885d9f215"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model trained\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.95      0.52      0.67       540\n",
            "        fear       0.86      0.47      0.61       442\n",
            "         joy       0.68      0.98      0.80      1335\n",
            "        love       0.97      0.17      0.30       332\n",
            "     sadness       0.76      0.94      0.84      1195\n",
            "    surprise       1.00      0.03      0.06       156\n",
            "\n",
            "    accuracy                           0.74      4000\n",
            "   macro avg       0.87      0.52      0.55      4000\n",
            "weighted avg       0.80      0.74      0.70      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"üîç Enter a sentence (type 'exit' to stop): \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"üëã Exiting manual prediction...\")\n",
        "        break\n",
        "    cleaned = clean_text(user_input)\n",
        "    vec = vectorizer.transform([cleaned])\n",
        "    pred = model.predict(vec)[0]\n",
        "    print(f\"üëâ Predicted Emotion: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtqEkDgDRgJs",
        "outputId": "37cfb0e6-5035-47ba-a11e-7156db33f7b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Enter a sentence (type 'exit' to stop): i am happy, today is really a good day\n",
            "üëâ Predicted Emotion: joy\n",
            "üîç Enter a sentence (type 'exit' to stop): i didnt expect this, things are going in a wrong way \n",
            "üëâ Predicted Emotion: sadness\n",
            "üîç Enter a sentence (type 'exit' to stop): exit\n",
            "üëã Exiting manual prediction...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def predict_emotion(text):\n",
        "    try:\n",
        "        cleaned = clean_text(text)\n",
        "        vec = vectorizer.transform([cleaned])\n",
        "        pred = model.predict(vec)[0]\n",
        "        probs = model.predict_proba(vec)[0]\n",
        "        prob_dict = dict(zip(model.classes_, probs))\n",
        "\n",
        "        plt.figure(figsize=(5, 3))\n",
        "        plt.bar(prob_dict.keys(), prob_dict.values(), color='skyblue')\n",
        "        plt.title(\"Emotion Confidence\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        plt.close()\n",
        "        buf.seek(0)\n",
        "        image = Image.open(buf)\n",
        "\n",
        "        return f\"**Predicted Emotion:** {pred}\", image\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\", None\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üß† Emotion Detection using Classical ML\")\n",
        "    inp = gr.Textbox(label=\"Enter text\")\n",
        "    out_text = gr.Markdown()\n",
        "    out_plot = gr.Image(type=\"pil\")\n",
        "    btn = gr.Button(\"Predict\")\n",
        "    btn.click(fn=predict_emotion, inputs=inp, outputs=[out_text, out_plot])\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "7LSBjyKtSFX-",
        "outputId": "47443703-d08d-41f9-cf77-18d8bc2c3a2a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1f81fdcf6a9617c17b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1f81fdcf6a9617c17b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}